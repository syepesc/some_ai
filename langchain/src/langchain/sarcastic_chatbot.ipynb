{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d34610f7-6682-4b08-80aa-d95917ea0145",
   "metadata": {},
   "source": [
    "# Sarcastic ChatBot\n",
    "\n",
    "Quick implemententaion of a sarcastic chatbot using OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46620a6-d6e5-49b2-8cdd-ed173018cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30b8aa-c20f-42aa-9dff-0fa06733dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set openai api key\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f6f852-0f39-41d1-99d8-e7f8d560f061",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b1fd32-2861-436f-bc93-6bc290cf6d33",
   "metadata": {},
   "source": [
    "# Chat Complition\n",
    "\n",
    "Read for more -> https://platform.openai.com/docs/api-reference/chat\n",
    "\n",
    "## Params\n",
    "\n",
    "- `model`: \"gpt-4|...\"\n",
    "\n",
    "- `messages`: The message parameter is a list of objects were you can specify prompts as diffrent roles. The object must contain:\n",
    "  - `role`: The role the model assume when answering a prompt/input.\n",
    "    - `system`: This role typically directs the model. Defines the model's purpose, persona, output, etc. e.i. _\"You are Mark and you will reluctantly answer questions with sarcastic responses\"_.\n",
    "    - `user`: This is the person (you) that is requesting the model to so something.\n",
    "    - `assistant`: This is use whenever we want to provide the model with example outputs. e.g. Classify positive or negative a comment.\n",
    "\n",
    "  - `content`: Your prompt.\n",
    "\n",
    "- `max_tokens`: Limits the model token outputs (long/short) responses.\n",
    "\n",
    "- `temperature`: Sets the model response randomnes, the bigger the value the more random a response can be. Accepts values between [0, 2].\n",
    "\n",
    "- `seed`: Control determinism of the model, equal responses are not guarantee but this helps getting similar responses if the seed is the same. Accepts any integer.\n",
    "\n",
    "- `stream`: Return stream responses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b29fb-feab-4b62-a214-026e4f9a81b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model = \"gpt-4\",\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are Mark and you will reluctantly answer questions with sarcastic responses\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Can you help me choosing a name for my dog?\",\n",
    "        },\n",
    "    ],\n",
    "    max_tokens = 250,\n",
    "    temperature = 0,\n",
    "    seed = 365,\n",
    "    stream = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f9ac3e-96b7-43d4-be6d-55606232f146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatCompletion stream object\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f48673-a8c6-4870-86b7-c798fe549834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model response\n",
    "for i in completion:\n",
    "    print(i.choices[0].delta.content, end = \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
